# Data-Analysis-From-Scratch
![ezgif-4-2e447eb075](https://github.com/user-attachments/assets/f8d41028-021d-4906-9a54-d7f4e77f0658)
<img width="611" alt="image" src="https://github.com/user-attachments/assets/1c637bc7-c79e-4200-b254-da0c252e700d" />
<img width="656" alt="image" src="https://github.com/user-attachments/assets/0785e056-5c9f-426e-b8c2-c3ee5eea2b04" />

Overview
This project demonstrates a comprehensive data analysis workflow using a Kaggle dataset. The analysis includes data manipulation, cleaning, and visualization using Python libraries, querying the data with PostgreSQL, exporting results to CSV files, and presenting insights with an interactive dashboard in Power BI.

Tools & Technologies Used:
Dataset: Kaggle
Python: Data manipulation, cleaning, and visualization (using libraries like Pandas, NumPy, Matplotlib and Seaborn).
PostgreSQL: Querying and analysis using Common Table Expressions (CTEs).
Excel: Exporting cleaned data to CSV.
Power BI: Building interactive dashboards.
Dataset
The dataset used for this project was sourced from Kaggle and contains a variety of features that were analyzed for trends and insights.

Kaggle Dataset Link
Steps & Process
1. Data Collection & Preprocessing (Python)
Importing Data: The dataset was imported into Python using the Pandas library.
Cleaning Data: Missing values, incorrect data types, and outliers were handled.
Data Transformation: Data was reshaped and transformed using Pandas and NumPy.
CSV Export: After cleaning, the dataset was exported to a CSV file using Python.

3. Exploratory Data Analysis (EDA) (Python)
Visualization: Various plots were created using Matplotlib and Seaborn to understand the data distribution and relationships between variables.
Histograms, Boxplots for distributions.
Scatter plots, Correlation Matrices for relationships.
Libraries Used:
Pandas
NumPy
Matplotlib
Seaborn

4. SQL Querying (CTEs)
Common Table Expressions (CTEs) were used to write complex SQL queries and break them down into manageable pieces.
CTEs helped aggregate data and filter specific insights.

5. Data Export to Excel (Python & Excel)
CSV Export: The cleaned data was exported as CSV using Pandas.to_csv() and reviewed in Excel for further analysis.
Excel Handling: Data refinement and preparation for Power BI was done in Excel.

7. Power BI Dashboard
Building Dashboard: An interactive dashboard was created using Power BI to present key insights.
Visualizations: Included bar charts, line graphs, and pie charts.
Interactivity: Filters and slicers were used to allow for in-depth exploration of the data.
Key Insights
The project uncovered various patterns such as:
Performance trends of categories over time.
Significant relationships and anomalies in the data.
Actionable insights for further business analysis or decision-making.
Installation & Usage
To replicate or extend this project, follow these steps:

1. Clone the repository
bash
Copy code
git clone https://github.com/your-username/data-analysis-project.git
cd data-analysis-project
2. Install Dependencies
Ensure you have Python and the required libraries installed. You can install the necessary libraries using pip:

bash
Copy code
pip install -r requirements.txt
3. Running the Scripts
Run the Python script for data manipulation and analysis:

bash
Copy code
python data_analysis.py
4. View the Dashboard
You can open the Power BI dashboard file (PowerBI_Dashboard.pbix) using Power BI Desktop to explore the interactive visualizations.

Future Improvements
Incorporating machine learning models for trend prediction.

Contact
Feel free to reach out for any queries or collaboration opportunities:

Email: [karantek27@gmail.com]
